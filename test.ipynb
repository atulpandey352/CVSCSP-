{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVSCSP_LDA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXD63n0iCk2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import scipy.signal\n",
        "import scipy.linalg as la\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.feature_selection import mutual_info_classif as MIBIF"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNrrpSUua9f7"
      },
      "source": [
        "class CVSCSP():\n",
        "    \n",
        "    def __init__(self, data_dict,fs,A=4,B=40,C=4, n_w = 2, n_features = 4, freqs_band = None, filter_order = 3, classifier = None, print_var = True):\n",
        "        self.fs = fs\n",
        "        self.trials_dict = data_dict\n",
        "        self.n_w = n_w\n",
        "        self.n_features = n_features\n",
        "        self.n_trials_class_1 = data_dict[list(data_dict.keys())[0]].shape[0]\n",
        "        self.n_trials_class_2 = data_dict[list(data_dict.keys())[1]].shape[0]\n",
        "        self.print_var = print_var\n",
        "        self.A=A\n",
        "        self.B=B\n",
        "        self.C=C\n",
        "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "        #Filter data section\n",
        "        \n",
        "        # Filtered signal list\n",
        "        self.filtered_band_signal_list = []\n",
        "        \n",
        "        # Frequencies band\n",
        "        freqs_band=self.fin()\n",
        "        only=[]\n",
        "        for arr in freqs_band:\n",
        "          if not np.array_equal(np.array([]), arr):\n",
        "            if not any(np.array_equal(arr, unique_arr) for unique_arr in only):\n",
        "              only.append(arr)\n",
        "        freqs_band=only\n",
        "        self.freqs = freqs_band\n",
        "        self.filterBankFunction(filter_order)\n",
        "       \n",
        "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -    \n",
        "        # CSP filters evaluation and application\n",
        "        \n",
        "        # CSP filter evaluation\n",
        "        self.W_list_band = []\n",
        "        self.evaluateW()\n",
        "        \n",
        "        # CSP filter application\n",
        "        self.features_band_list = []\n",
        "        self.spatialFilteringAndFeatureExtraction()\n",
        "        \n",
        "        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
        "        # Training of the classifier\n",
        "        if(classifier != None): self.trainClassifier(classifier = classifier)\n",
        "        else: self.trainClassifier() \n",
        "        \n",
        "    def fin(self):\n",
        "      li=[]\n",
        "      A=self.A\n",
        "      B=self.B\n",
        "      C=self.C\n",
        "      au=np.array([A,B])\n",
        "      li.append(au)\n",
        "      def mun(A,B):\n",
        "        if ((B-A)<C):\n",
        "          return 0,0\n",
        "        else :\n",
        "          m=np.array([(A+C),B])\n",
        "          n= np.array([A,(B-C)])\n",
        "          if (m[1]==m[0]):\n",
        "            return np.array([0,0]),np.array([0,0])\n",
        "          else :\n",
        "            return m,n \n",
        "\n",
        "      count=1\n",
        "      while ((li[len(li)-1][1]-li[len(li)-1][0])>=C):\n",
        "    \n",
        "        ki=[]\n",
        "        for i in range(0,count):\n",
        "          r,s=mun(li[len(li)-i-1][0],li[len(li)-i-1][1])\n",
        "          if(r[1]-r[0]<C):\n",
        "            return li\n",
        "          else:   \n",
        "            ki.append(r)\n",
        "            ki.append(s)\n",
        "      \n",
        "        li=li+ki\n",
        "        count=count+1  \n",
        "      return li    \n",
        "        \n",
        "    def filterBankFunction(self, filter_order = 3):\n",
        "        \"\"\"\n",
        "        Function that apply fhe fitlering for each pair of frequencies in the list self.freqs.\n",
        "        The results are saved in a list called self.filtered_band_signal_list. Each element of the list is a diciotinary with key the label of the various class.\n",
        "        Parameters\n",
        "        ----------\n",
        "        filter_order : int, optional\n",
        "            The order of the filter. The default is 3.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Cycle for the frequency bands\n",
        "        for i in range(len(self.freqs)):  \n",
        "            # Dict for selected band that will contain the various filtered signals\n",
        "            filt_trial_dict = {}\n",
        "            \n",
        "            # \"Create\" the band\n",
        "            band = [self.freqs[i][1], self.freqs[i][0]]\n",
        "            \n",
        "            # Cycle for the classes\n",
        "            for key in self.trials_dict.keys(): \n",
        "                # Filter the signal in each class for the selected frequency band\n",
        "                filt_trial_dict[key] = self.bandFilterTrials(self.trials_dict[key], band[0], band[1], filter_order = filter_order)\n",
        "            \n",
        "            # Save the filtered signal in the list\n",
        "            self.filtered_band_signal_list.append(filt_trial_dict)\n",
        "        \n",
        "    \n",
        "    def bandFilterTrials(self, trials_matrix, low_f, high_f, filter_order = 3):\n",
        "        \"\"\"\n",
        "        Applying a pass-band fitlering to the data. The filter implementation was done with scipy.signal\n",
        "    \n",
        "        Parameters\n",
        "        ----------\n",
        "        trials_matrix : numpy matrix\n",
        "            Numpy matrix with the various EEG trials. The dimensions of the matrix must be n_trial x n_channel x n_samples\n",
        "        fs : int/double\n",
        "            Frequency sampling.\n",
        "        low_f : int/double\n",
        "            Low band of the pass band filter.\n",
        "        high_f : int/double\n",
        "            High band of the pass band filter..\n",
        "        filter_order : int, optional\n",
        "            Order of the filter. The default is 3.\n",
        "    \n",
        "        Returns\n",
        "        -------\n",
        "        filter_trails_matrix : numpy matrix\n",
        "             Numpy matrix with the various filtered EEG trials. The dimensions of the matrix must be n_trial x n_channel x n_samples.\n",
        "    \n",
        "        \"\"\"\n",
        "        \n",
        "        # Evaluate low buond and high bound in the [0, 1] range\n",
        "        low_bound = low_f / (self.fs/2)\n",
        "        high_bound = high_f / (self.fs/2)\n",
        "        \n",
        "        # Check input data\n",
        "        if(low_bound < 0): low_bound = 0\n",
        "        if(high_bound > 1): high_bound = 1\n",
        "        if(low_bound > high_bound): low_bound, high_bound = high_bound, low_bound\n",
        "        if(low_bound == high_bound): low_bound, high_bound = 0, 1\n",
        "        \n",
        "        b, a = scipy.signal.butter(filter_order, [low_bound, high_bound], 'bandpass')\n",
        "          \n",
        "        return scipy.signal.filtfilt(b, a, trials_matrix)\n",
        "    \n",
        "    \n",
        "    def evaluateW(self):\n",
        "        \"\"\"\n",
        "        Evaluate the spatial filter of the CSP algorithm for each filtered signal inside self.filtered_band_signal_list\n",
        "        Results are saved inside self.W_list_band.    \n",
        "        \"\"\"\n",
        "        \n",
        "        for filt_trial_dict in self.filtered_band_signal_list:\n",
        "            # Retrieve the key (class)\n",
        "            keys = list(filt_trial_dict.keys())\n",
        "            \n",
        "            \n",
        "            keys = list(filt_trial_dict.keys())\n",
        "            trials_1 = filt_trial_dict[keys[0]]\n",
        "            trials_2 = filt_trial_dict[keys[1]]\n",
        "        \n",
        "            # Evaluate covariance matrix for the two classes\n",
        "            cov_1 = self.trialCovariance(trials_1)\n",
        "            cov_2 = self.trialCovariance(trials_2)\n",
        "            R = cov_1 + cov_2\n",
        "            \n",
        "            # Evaluate whitening matrix\n",
        "            P = self.whitening(R)\n",
        "            \n",
        "            # The mean covariance matrices may now be transformed\n",
        "            cov_1_white = np.dot(P, np.dot(cov_1, np.transpose(P)))\n",
        "            cov_2_white = np.dot(P, np.dot(cov_2, np.transpose(P)))\n",
        "            \n",
        "            # Since CSP requires the eigenvalues and eigenvector be sorted in descending order we find and sort the generalized eigenvalues and eigenvector\n",
        "            E, U = la.eig(cov_1_white, cov_2_white)\n",
        "            order = np.argsort(E)\n",
        "            order = order[::-1]\n",
        "            E = E[order]\n",
        "            U = U[:, order]\n",
        "            \n",
        "            # The projection matrix (the spatial filter) may now be obtained\n",
        "            W = np.dot(np.transpose(U), P)\n",
        "            \n",
        "            self.W_list_band.append(W)\n",
        "      \n",
        "    \n",
        "    def trialCovariance(self, trials):\n",
        "        \"\"\"\n",
        "        Calculate the covariance for each trial and return their average\n",
        "    \n",
        "        Parameters\n",
        "        ----------\n",
        "        trials : numpy 3D-matrix\n",
        "            Trial matrix. The dimensions must be trials x channel x samples\n",
        "    \n",
        "        Returns\n",
        "        -------\n",
        "        mean_cov : Numpy matrix\n",
        "            Mean of the covariance alongside channels.\n",
        "    \n",
        "        \"\"\"\n",
        "        \n",
        "        n_trials, n_channels, n_samples = trials.shape\n",
        "        \n",
        "        covariance_matrix = np.zeros((n_trials, n_channels, n_channels))\n",
        "        \n",
        "        for i in range(trials.shape[0]):\n",
        "            trial = trials[i, :, :]\n",
        "            covariance_matrix[i, :, :] = np.cov(trial)\n",
        "            \n",
        "        mean_cov = np.mean(covariance_matrix, 0)\n",
        "            \n",
        "        return mean_cov\n",
        "    \n",
        "    \n",
        "    def whitening(self, sigma, mode = 2):\n",
        "        \"\"\"\n",
        "        Calculate the whitening matrix for the input matrix sigma\n",
        "    \n",
        "        Parameters\n",
        "        ----------\n",
        "        sigma : Numpy square matrix\n",
        "            Input matrix.\n",
        "        mode : int, optional\n",
        "            Select how to evaluate the whitening matrix. The default is 1.\n",
        "    \n",
        "        Returns\n",
        "        -------\n",
        "        x : Numpy square matrix\n",
        "            Whitening matrix.\n",
        "        \"\"\"\n",
        "        [u, s, vh] = np.linalg.svd(sigma)\n",
        "        \n",
        "          \n",
        "        if(mode != 1 and mode != 2): mode == 1\n",
        "        \n",
        "        if(mode == 1):\n",
        "            # Whitening constant: prevents division by zero\n",
        "            epsilon = 1e-5\n",
        "            \n",
        "            # ZCA Whitening matrix: U * Lambda * U'\n",
        "            x = np.dot(u, np.dot(np.diag(1.0/np.sqrt(s + epsilon)), u.T))\n",
        "        else:\n",
        "            # eigenvalue decomposition of the covariance matrix\n",
        "            d, V = np.linalg.eigh(sigma)\n",
        "            fudge = 10E-18\n",
        "         \n",
        "            # A fudge factor can be used so that eigenvectors associated with small eigenvalues do not get overamplified.\n",
        "            D = np.diag(1. / np.sqrt(d+fudge))\n",
        "         \n",
        "            # whitening matrix\n",
        "            x = np.dot(np.dot(V, D), V.T)\n",
        "            \n",
        "        return x\n",
        "        \n",
        "    \n",
        "    def spatialFilteringAndFeatureExtraction(self):\n",
        "        # Cycle through frequency band and relative CSP filter\n",
        "        for filt_trial_dict, W in zip(self.filtered_band_signal_list, self.W_list_band):\n",
        "            # Features dict for the current frequency band\n",
        "            features_dict = {}\n",
        "            \n",
        "            # Cycle through the classes\n",
        "            for key in filt_trial_dict.keys():\n",
        "                # Applying spatial filter\n",
        "                tmp_trial = self.spatialFilteringW(filt_trial_dict[key], W)\n",
        "                \n",
        "                # Features evaluation\n",
        "                features_dict[key] = self.logVarEvaluation(tmp_trial)\n",
        "            \n",
        "            self.features_band_list.append(features_dict)\n",
        "        \n",
        "        # Evaluate mutual information between features\n",
        "        self.mutual_information_list = self.computeFeaturesMutualInformation()\n",
        "        #print((len(self.mutual_information_list),self.mutual_information_list[8].shape))\n",
        "\n",
        "        self.mutual_information_vector, self.other_info_matrix = self.changeShapeMutualInformationList()\n",
        "        \n",
        "        # Select features to use for classification\n",
        "        self.classifier_features = self.selectFeatures()\n",
        "        \n",
        "        \n",
        "    def spatialFilteringW(self, trials, W):\n",
        "        # Allocate memory for the spatial fitlered trials\n",
        "        trials_csp = np.zeros(trials.shape)\n",
        "        \n",
        "        # Apply spatial fitler\n",
        "        for i in range(trials.shape[0]): trials_csp[i, :, :] = W.dot(trials[i, :, :])\n",
        "            \n",
        "        return trials_csp\n",
        "    \n",
        "    \n",
        "    def logVarEvaluation(self, trials):\n",
        "        \"\"\"\n",
        "        Evaluate the log (logarithm) var (variance) of the trial matrix along the samples axis.\n",
        "        The sample axis is the axis number 2, counting axis as 0,1,2. \n",
        "    \n",
        "        Parameters\n",
        "        ----------\n",
        "        trials : numpy 3D-matrix\n",
        "            Trial matrix. The dimensions must be trials x channel x samples\n",
        "    \n",
        "        Returns\n",
        "        -------\n",
        "        features : Numpy 2D-matrix\n",
        "            Return the features matrix. DImension will be trials x channel\n",
        "    \n",
        "        \"\"\"\n",
        "        # Select the first and last n rows of the CSP filtered signal\n",
        "        idx = []\n",
        "        for i in range(self.n_w): idx.append(i)\n",
        "        for i in reversed(idx): idx.append(-(i + 1))\n",
        "        trials = trials[:, idx, :]    \n",
        "        \n",
        "        features = np.var(trials, 2)\n",
        "        features = np.log(features)\n",
        "        \n",
        "        return features\n",
        "    \n",
        "    \n",
        "    def featuresEvaluation(self, trials, W):\n",
        "        \"\"\"\n",
        "        Alternative method for features evaluation.\n",
        "        Implemented but not used. Very low performance\n",
        "        \"\"\"\n",
        "        \n",
        "        # Create index for select the first and last n column and select them\n",
        "        idx = []\n",
        "        for i in range(self.n_features): idx.append(i)\n",
        "        for i in reversed(idx): idx.append(-(i + 1))\n",
        "        W_bar = W[:, idx]\n",
        "        \n",
        "        # Variable for the trials features\n",
        "        features = np.zeros((trials.shape[0], self.n_features * 2))\n",
        "        \n",
        "        for i in range(trials.shape[0]):\n",
        "            trial = trials[i, : , :]\n",
        "            \n",
        "            part_1 = (W_bar.T).dot(trial)\n",
        "            part_2 = (trial.T).dot(W_bar)\n",
        "            \n",
        "            tmp_element = part_1.dot(part_2)\n",
        "            \n",
        "            num = np.diag(tmp_element)\n",
        "            den = np.trace(tmp_element)\n",
        "            \n",
        "            features[i, :] = np.log(num/den)\n",
        "            \n",
        "        return features\n",
        "            \n",
        "            \n",
        "    def computeFeaturesMutualInformation(self):\n",
        "        \"\"\"\n",
        "        Select the first and last n columns of the various features matrix and compute their mutual inforamation.\n",
        "        The value of n is self.n_features\n",
        "        Returns\n",
        "        -------\n",
        "        mutual_information_list : List of numpy matrix\n",
        "            List with the mutual information of the various features.\n",
        "        \"\"\"\n",
        "        \n",
        "        mutual_information_list = []\n",
        "                \n",
        "        # Cycle through the different band\n",
        "        for features_dict in self.features_band_list:\n",
        "            # Retrieve features for that band\n",
        "            keys = list(features_dict.keys())\n",
        "            feat_1 = features_dict[keys[0]]\n",
        "            feat_2 = features_dict[keys[1]]\n",
        "            \n",
        "            # Save features in a single matrix\n",
        "            all_features = np.zeros((feat_1.shape[0] + feat_2.shape[0], feat_1.shape[1]))            \n",
        "            all_features[0:feat_1.shape[0], :] = feat_1\n",
        "            all_features[feat_1.shape[0]:, :] = feat_2\n",
        "            \n",
        "            # Create label vector\n",
        "            label = np.ones(all_features.shape[0])\n",
        "            label[0:feat_1.shape[0]] = 2\n",
        "            \n",
        "            tmp_mutual_information = MIBIF(all_features, label)\n",
        "            mutual_information_list.append(tmp_mutual_information)\n",
        "              \n",
        "        return mutual_information_list\n",
        "    \n",
        "    \n",
        "    def changeShapeMutualInformationList(self):\n",
        "        # 1D-Array with all the mutual information value\n",
        "        mutual_information_vector = np.zeros(4*len(self.mutual_information_list))\n",
        "            \n",
        "        # Since the CSP features are coupled (First with last etc) in this matrix I save the couple.\n",
        "        # I will also save the original band and the position in the original band\n",
        "        other_info_matrix = np.zeros((len(mutual_information_vector), 4))\n",
        "        \n",
        "        for i in range(len(self.mutual_information_list)):\n",
        "            mutual_information = self.mutual_information_list[i]\n",
        "            \n",
        "            for j in range(self.n_w * 2):\n",
        "                # Acual index for the various vector\n",
        "                actual_idx = i * self.n_w * 2 + j\n",
        "                \n",
        "                # Save the current value of mutual information for that features\n",
        "                mutual_information_vector[actual_idx] = mutual_information[j]\n",
        "                \n",
        "                # Save other information related to that feature\n",
        "                other_info_matrix[actual_idx, 0] = i * self.n_w * 2 + ((self.n_w * 2) - (j + 1)) # Position of the twin (in the vector)\n",
        "                other_info_matrix[actual_idx, 1] = actual_idx # Position of the actual feature (in the vector)\n",
        "                other_info_matrix[actual_idx, 2] = i # Current band\n",
        "                other_info_matrix[actual_idx, 3] = j # Position in the original band\n",
        "                \n",
        "        return mutual_information_vector, other_info_matrix\n",
        "    \n",
        "    \n",
        "    def computeMutualInformation2(self):\n",
        "        \"\"\"\n",
        "        Method add to test a different type of mutual information evaluation find in another paper. \n",
        "        The results are the same that with the original method. \n",
        "        So this method is impemented but not used.\n",
        "        \"\"\"\n",
        "\n",
        "        tot_trials = self.n_trials_class_1 + self.n_trials_class_2\n",
        "        features_matrix = np.zeros((tot_trials, self.n_features * 2 * 9))\n",
        "        label_vector = np.zeros(tot_trials)\n",
        "        \n",
        "        # Cycle through the different band\n",
        "        for features_dict, i in zip(self.features_band_list, range(len(self.features_band_list))):\n",
        "            # Retrieve features for that band\n",
        "            keys = list(features_dict.keys())\n",
        "            feat_1 = features_dict[keys[0]]\n",
        "            feat_2 = features_dict[keys[1]]\n",
        "            \n",
        "            # Save features in a single matrix\n",
        "            all_features = np.zeros((feat_1.shape[0] + feat_2.shape[0], self.n_features * 2))            \n",
        "            all_features[0:feat_1.shape[0], :] = feat_1\n",
        "            all_features[feat_1.shape[0]:, :] = feat_2\n",
        "            \n",
        "            # Create label vector\n",
        "            label = np.ones(all_features.shape[0])\n",
        "            label[0:feat_1.shape[0]] = 2\n",
        "            \n",
        "            # Add element to the single variable\n",
        "            features_matrix[0:tot_trials, (self.n_features * 2) * i:(self.n_features * 2) * (i + 1)] = all_features\n",
        "            label_vector[0:tot_trials] = label\n",
        "            \n",
        "        \n",
        "        self.mutual_information_vector_V2 = MIBIF(features_matrix, label_vector)\n",
        "            \n",
        "    \n",
        "    def selectFeatures(self):\n",
        "        \"\"\"\n",
        "        Select n features for classification. In this case n is equal to 2 * self.n_features.\n",
        "        The features selected are the self.n_features with the highest mutual information. \n",
        "        Since the CSP features are coupled if the original couple was not selected we add to the list of features the various couple.\n",
        "        The original algorithm select a variable number of features (and also the V3 implementation has the same behavior). This version select always 2 * self.n_features.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        complete_list_of_features : List of tuple\n",
        "            List that contatin the band for the filter and the position inside the original band.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Sort features in order of mutual information\n",
        "        sorted_MI_features_index = np.flip(np.argsort(self.mutual_information_vector))\n",
        "        sorted_other_info = self.other_info_matrix[sorted_MI_features_index, :]\n",
        "        \n",
        "        complete_list_of_features = []\n",
        "        selected_features = sorted_other_info[:, 1][0:self.n_features]\n",
        "        \n",
        "        for i in range(self.n_features):\n",
        "            # Current features (NOT USED)(added just for clarity during coding)\n",
        "            # current_features = sorted_other_info[i, 1]\n",
        "            \n",
        "            # Twin/Couple feature of the current features\n",
        "            current_features_twin = sorted_other_info[i, 0]\n",
        "            \n",
        "            if(current_features_twin in selected_features): \n",
        "                # If I also select its counterpart I only add the current feaures because the counterpart will be added in future iteration of the cycle\n",
        "                \n",
        "                # Save the features as tuple with (original band, original position in the original band)\n",
        "                features_item = (int(sorted_other_info[i, 2]), int(sorted_other_info[i, 3]))\n",
        "                \n",
        "                # Add the element to the features vector\n",
        "                complete_list_of_features.append(features_item)\n",
        "            else: \n",
        "                # If I not select its counterpart I addo both the current features and it's counterpart\n",
        "                \n",
        "                # Select and add the current feature\n",
        "                features_item = (int(sorted_other_info[i, 2]), int(sorted_other_info[i, 3]))\n",
        "                complete_list_of_features.append(features_item)\n",
        "                \n",
        "                # Select and add the twin/couple feature\n",
        "                idx = sorted_other_info[:, 1] == current_features_twin\n",
        "                features_item = (int(sorted_other_info[idx, 2][0]), int(sorted_other_info[idx, 3][0]))\n",
        "                complete_list_of_features.append(features_item)\n",
        "                \n",
        "        return sorted(complete_list_of_features)\n",
        "    \n",
        "    \n",
        "    def extractFeaturesForTraining(self):\n",
        "        # Tracking variable of the band\n",
        "        old_band = -1\n",
        "        \n",
        "        # Return matrix\n",
        "        features_1 = np.zeros((self.n_trials_class_1, len(self.classifier_features)))\n",
        "        features_2 = np.zeros((self.n_trials_class_2, len(self.classifier_features)))\n",
        "        \n",
        "        # Cycle through the different features\n",
        "        for i in range(len(self.classifier_features)):\n",
        "            # Retrieve the position of the features\n",
        "            features_position = self.classifier_features[i]\n",
        "            \n",
        "            # Band of the selected feaures\n",
        "            current_features_band = features_position[0]\n",
        "            \n",
        "            # Check if the band is the same of the previous iteration\n",
        "            if(current_features_band != old_band):\n",
        "                # In this case the band is not the same of the previous iteration\n",
        "                \n",
        "                old_band = current_features_band\n",
        "                \n",
        "                # Retrieve the dictionary with the features of the two classes for the current band\n",
        "                current_band_features_dict = self.features_band_list[current_features_band]\n",
        "                \n",
        "                # Retrieve the matrix of features for the two classes\n",
        "                keys = list(current_band_features_dict.keys())\n",
        "                tmp_feat_1 = current_band_features_dict[keys[0]]\n",
        "                tmp_feat_2 = current_band_features_dict[keys[1]]\n",
        "                \n",
        "                # Extract the features\n",
        "                features_1[:, i] = tmp_feat_1[:, features_position[1]]\n",
        "                features_2[:, i] = tmp_feat_2[:, features_position[1]]\n",
        "                \n",
        "            else: \n",
        "                # In this case I'm in the same band of the previous iteration\n",
        "                \n",
        "                # Extract the features\n",
        "                features_1[:, i] = tmp_feat_1[:, features_position[1]]\n",
        "                features_2[:, i] = tmp_feat_2[:, features_position[1]]\n",
        "        \n",
        "                \n",
        "        return features_1, features_2\n",
        "    \n",
        "        \n",
        "    def trainClassifier(self, train_ratio = 0.75, classifier = None):\n",
        "        \"\"\"\n",
        "        Divide the data in train set and test set and used the data to train the classifier.\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_features : int, optional\n",
        "            The number of mixture channel to use in the classifier. It must be even and at least as big as 2. The default is 2.\n",
        "        train_ratio : doble, optional\n",
        "            The proportion of the data to used as train dataset. The default is 0.75.\n",
        "        classifier : sklearnn classifier, optional\n",
        "            Classifier used for the problem. It must be a sklearn classifier. If no classfier was provided the fucntion use the LDA classifier.\n",
        "        \"\"\"\n",
        "        \n",
        "        features_1, features_2 = self.extractFeaturesForTraining()\n",
        "        self.n_features_for_classification = features_1.shape[1]\n",
        "        if(self.print_var): print(\"Features used for classification: \", self.n_features_for_classification)\n",
        "    \n",
        "        # Save both features in a single data matrix\n",
        "        data_matrix = np.zeros((features_1.shape[0] + features_2.shape[0], features_1.shape[1]))\n",
        "        data_matrix[0:features_1.shape[0], :] = features_1\n",
        "        data_matrix[features_1.shape[0]:, :] = features_2\n",
        "        self.tmp_data_matrix = data_matrix\n",
        "        \n",
        "        # Create the label vector\n",
        "        label = np.zeros(data_matrix.shape[0])\n",
        "        label[0:features_1.shape[0]] = 1\n",
        "        label[features_1.shape[0]:] = 2\n",
        "        self.tmp_label = label\n",
        "        \n",
        "        # Create the label dict\n",
        "        self.tmp_label_dict = {}\n",
        "        keys = list(self.features_band_list[0].keys())\n",
        "        self.tmp_label_dict[1] = keys[0]\n",
        "        self.tmp_label_dict[2] = keys[1]\n",
        "        \n",
        "        # Shuffle the data\n",
        "        perm = np.random.permutation(len(label))\n",
        "        label = label[perm]\n",
        "        data_matrix = data_matrix[perm, :]\n",
        "        \n",
        "        # Select the portion of data used during training\n",
        "        if(train_ratio <= 0 or train_ratio >= 1): train_ratio = 0.75\n",
        "        index_training = int(data_matrix.shape[0] * train_ratio)\n",
        "        train_data = data_matrix[0:index_training, :]\n",
        "        train_label = label[0:index_training]\n",
        "        test_data = data_matrix[index_training:, :]\n",
        "        test_label = label[index_training:]\n",
        "        self.tmp_train = [train_data, train_label]\n",
        "        self.tmp_test = [test_data, test_label]\n",
        "        \n",
        "        # Select classifier\n",
        "        if(classifier == None): self.classifier = LDA()\n",
        "        else: self.classifier = classifier\n",
        "        \n",
        "        # Train Classifier\n",
        "        self.classifier.fit(train_data, train_label)\n",
        "        if(self.print_var): print(\"Accuracy on TRAIN set: \", self.classifier.score(train_data, train_label))\n",
        "        \n",
        "        # Test parameters\n",
        "        if(self.print_var): print(\"Accuracy on TEST set: \", self.classifier.score(test_data, test_label), \"\\n\")\n",
        "        \n",
        "        # print(\"total: \", self.classifier.score(train_data, train_label) * self.classifier.score(test_data, test_label))\n",
        "        \n",
        "        \n",
        "    def evaluateTrial(self, trials_matrix, plot = True):\n",
        "        \"\"\"\n",
        "        Evalaute trial/trials given in input\n",
        "        Parameters\n",
        "        ----------\n",
        "        trials_matrix : Numpy 3D matrix\n",
        "            Input matrix of trials. The dimension MUST BE \"n. trials x n. channels x n.samples\".\n",
        "            Also in case of single trials the input input dimension must be \"1 x n. channels x n.samples\".\n",
        "        plot : Boolean, optional\n",
        "            If set to true will plot the features of the trial. The default is True.\n",
        "        Returns\n",
        "        -------\n",
        "        y : Numpy vector\n",
        "            Vector with the label of the respective trial. The length of the vector is the number of trials.\n",
        "            The label are 1 for class 1 and 2 for class 2.\n",
        "        \n",
        "        y_prob : Numpy matrix\n",
        "            Vector with the label of the respective trial. The length of the vector is the number of trials.\n",
        "            The label are 1 for class 1 and 2 for class 2.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Compute and extract the features for the training\n",
        "        features_input = self.extractFeatures(trials_matrix)\n",
        "        self. a = features_input\n",
        "\n",
        "        # Classify the trials\n",
        "        # print(features_input.shape)\n",
        "        y = self.classifier.predict(features_input)\n",
        "        \n",
        "        # Evaluate the probabilty\n",
        "        # if(self.classifier.__class__.__name__ == 'LinearDiscriminantAnalysis'):\n",
        "        #     y_prob = self.classifier.predict_proba(features_input)\n",
        "        # else:\n",
        "        #     y_prob = np.zeros(2)\n",
        "            \n",
        "        y_prob = self.classifier.predict_proba(features_input)\n",
        "        \n",
        "        return y, y_prob\n",
        "    \n",
        "    \n",
        "    def extractFeatures(self, trials_matrix): \n",
        "        # List for the features\n",
        "        features_list = []\n",
        "        \n",
        "        # Input for the classifier\n",
        "        features_input = np.zeros((trials_matrix.shape[0], len(self.classifier_features)))\n",
        "        \n",
        "        # Frequency filtering, spatial filtering, features evaluation\n",
        "        for i in range(len(self.freqs) - 1):              \n",
        "            # \"Create\" the band\n",
        "            band = [self.freqs[i], self.freqs[i+1]]\n",
        "            \n",
        "            # Retrieve spatial filter\n",
        "            W = self.W_list_band[i]\n",
        "            \n",
        "            # Frequency and spatial filter\n",
        "            band_filter_trials_matrix = self.bandFilterTrials(trials_matrix, band[0], band[1])\n",
        "            spatial_filter_trial = self.spatialFilteringW(band_filter_trials_matrix, W)\n",
        "            \n",
        "            # Features evaluation\n",
        "            features = self.logVarEvaluation(spatial_filter_trial)\n",
        "            \n",
        "            features_list.append(features)\n",
        "            # features_list.append(features[:, idx])\n",
        "            \n",
        "        # Features selection\n",
        "        for i in range(len(self.classifier_features)):\n",
        "            # Retrieve feature position\n",
        "            feature_position = self.classifier_features[i]\n",
        "            \n",
        "            # Retrieve feature from the evaluated features\n",
        "            features_input[:, i] = features_list[feature_position[0]][:, feature_position[1]]\n",
        "            \n",
        "        return features_input\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwCjlrPPJSeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80f4f61-5352-4e03-98a0-5b1c76407bd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jxwA8KWjNiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3709e20-916f-4731-fa38-ee75d8ad81ee"
      },
      "source": [
        "pip install mne"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-0.23.0-py3-none-any.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 15.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.23.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu_j6dl8jFTI"
      },
      "source": [
        "import mne\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcH1MJ41NCY3"
      },
      "source": [
        "# CREATING DATA DICTIONARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdZuXv_j2NMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa42003-665b-4382-8a80-9c894405445e"
      },
      "source": [
        "  nam=['a','b','c','d','e','f']\n",
        "  for i in nam:\n",
        "    temp=loadmat('gdrive/My Drive/po/so/BCICIV_calib_ds1'+i +'_1000Hz.mat')\n",
        "    labels= []\n",
        "    clab=temp['nfo'][0][0]['clab']   \n",
        "    for i in range(0,len(clab[0])) :\n",
        "      a = str(clab[0][i][0])\n",
        "      labels.append(a)\n",
        "    mp = temp['cnt']\n",
        "    info=mne.create_info(ch_names=labels,sfreq=temp['nfo']['fs'][0][0][0][0],ch_types='eeg',verbose=None)\n",
        "    raw=mne.io.RawArray(mp.T,info) \n",
        "    pos=temp['mrk'][0][0]['pos']\n",
        "    y= temp['mrk'][0][0]['y']\n",
        "    pos=temp['mrk'][0][0]['pos']\n",
        "    y= temp['mrk'][0][0]['y']\n",
        "    p=np.empty((200,1),dtype='int64')\n",
        "    p[:,0]=pos[0]\n",
        "    yl=np.empty((200,1),dtype='int64') \n",
        "    yl[:,0]=y[0]\n",
        "    e=np.zeros((p.shape),dtype='int64')\n",
        "    events=np.concatenate((p,e,yl),axis=1)\n",
        "    events_id = {'Left': -1, 'right': 1} \n",
        "  \n",
        "   \n",
        "    # creating epochs dataset\n",
        "  \n",
        "    tmin, tmax = 0.5, 2.5\n",
        "    epochs = mne.Epochs(raw, events, events_id, tmin, tmax, proj=True,\n",
        "                   picks=('eeg'), baseline=(None, None), preload=True)\n",
        "    epochs.resample(100)                # downsampling our data for easy compytation\n",
        "    epochs_data = epochs.get_data()\n",
        "    x=epochs_data\n",
        "    labels=y[0]\n",
        "    t_one= x[labels[:]==1][:][:]\n",
        "    t_none = x[labels[:]==-1][:][:]\n",
        "    fb_data= {'-1':t_none, '1':t_one}    # creating data dictionary\n",
        "    K=CVSCSP(fb_data,100)\n",
        "\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating RawArray with float64 data, n_channels=59, n_times=1905940\n",
            "    Range : 0 ... 1905939 =      0.000 ...  1905.939 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.9533333333333334\n",
            "Accuracy on TEST set:  0.88 \n",
            "\n",
            "Creating RawArray with float64 data, n_channels=59, n_times=1905940\n",
            "    Range : 0 ... 1905939 =      0.000 ...  1905.939 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.96\n",
            "Accuracy on TEST set:  0.9 \n",
            "\n",
            "Creating RawArray with float64 data, n_channels=59, n_times=1905499\n",
            "    Range : 0 ... 1905498 =      0.000 ...  1905.498 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.9333333333333333\n",
            "Accuracy on TEST set:  0.94 \n",
            "\n",
            "Creating RawArray with float64 data, n_channels=59, n_times=1904735\n",
            "    Range : 0 ... 1904734 =      0.000 ...  1904.734 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.98\n",
            "Accuracy on TEST set:  0.98 \n",
            "\n",
            "Creating RawArray with float64 data, n_channels=59, n_times=1903295\n",
            "    Range : 0 ... 1903294 =      0.000 ...  1903.294 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.9733333333333334\n",
            "Accuracy on TEST set:  1.0 \n",
            "\n",
            "Creating RawArray with float64 data, n_channels=59, n_times=1906080\n",
            "    Range : 0 ... 1906079 =      0.000 ...  1906.079 secs\n",
            "Ready.\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "200 matching events found\n",
            "Setting baseline interval to [0.5, 2.5] sec\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 200 events and 2001 original time points ...\n",
            "0 bad epochs dropped\n",
            "Features used for classification:  8\n",
            "Accuracy on TRAIN set:  0.9466666666666667\n",
            "Accuracy on TEST set:  0.96 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}